---
id: data_pipeline
schedule: "0 0 2 * * *"  # 2 AM daily
---

# Data Pipeline

A comprehensive ETL pipeline for processing daily data. This demonstrates
task dependencies, configuration, and environment variables in POML format.

## Configuration

- batch_size: 1000
- output_dir: /tmp/data

## Extract

Extracts data from the source database.

- **type**: command
- **command**: echo
- **args**: ["Extracting data..."]
- **environment**:
  - STAGE: extract

## Transform

Transforms the extracted data.

- **type**: command
- **command**: echo
- **args**: ["Transforming data..."]
- **depends_on**: [Extract](#extract)
- **environment**:
  - STAGE: transform

## Validate

Validates the transformed data.

- **type**: command
- **command**: echo
- **args**: ["Validating data..."]
- **depends_on**: [Transform](#transform)
- **condition**: all_success

## Load

Loads the transformed data to the destination.

- **type**: command
- **command**: echo
- **args**: ["Loading data to destination..."]
- **depends_on**: [Validate](#validate)
- **condition**: all_success

## Notify Success

Notifies that the pipeline completed successfully.

- **type**: command
- **command**: echo
- **args**: ["Pipeline completed successfully!"]
- **depends_on**: [Load](#load)
- **condition**: all_done
